# generated by datamodel-codegen:
#   filename:  mdq.yml
#   timestamp: 2025-04-18T03:03:08+00:00

from enum import Enum
from typing import Annotated, Any, Literal

from pydantic import BaseModel, Field, RootModel


Timeout = RootModel[
    Annotated[
        str,
        Field(
            description="The maximum time in seconds that the answer key can run. If the answer key runs for more than this time, it is considered to be stuck and the execution is aborted.\n",
            pattern="[0-9]+(.[0-9]+)?%",
        ),
    ]
]


FieldAssociativeItemKeyImage = RootModel[Any]
FieldAssociativeItemKeyText = RootModel[Any]
Key = str
ForbiddenSyntax21 = RootModel[Annotated[dict[str, float], Field(min_length=1)]]
ForbiddenSyntax22Item = RootModel[Annotated[str, Field(min_length=1)]]
ForbiddenSyntax22 = RootModel[
    Annotated[list[ForbiddenSyntax22Item], Field(min_length=1)]
]
ForbiddenSyntaxItem = RootModel[Annotated[str, Field(min_length=1)]]

FieldForbiddenFeature = RootModel[Annotated[str, Field(min_length=1)]]
FieldForbiddenFeatures1Item = RootModel[Annotated[str, Field(min_length=1)]]

FieldForbiddenFeatures1 = RootModel[
    Annotated[dict[str, list[FieldForbiddenFeatures1Item]], Field(min_length=1)]
]
FieldForbiddenFeatures = RootModel[
    list[FieldForbiddenFeature] | FieldForbiddenFeatures1
]

ForbiddenSyntax = RootModel[
    Annotated[
        list[ForbiddenSyntaxItem],
        Field(
            description="A mapping of keywords (if, for, etc) with the maximum number of times they can  occur in the code.\n",
            min_length=1,
        ),
    ]
]
ForbiddenSyntax1 = RootModel[
    Annotated[
        dict[str, float],
        Field(
            description="A mapping of keywords (if, for, etc) with the maximum number of times they can  occur in the code.\n",
            min_length=1,
        ),
    ]
]

ForbiddenSyntax2 = RootModel[
    Annotated[
        dict[str, ForbiddenSyntax21 | ForbiddenSyntax22],
        Field(
            description="A mapping of keywords (if, for, etc) with the maximum number of times they can  occur in the code.\n",
            min_length=1,
        ),
    ]
]

"""
A list of programming languages that can be used in the essay question. The list is not exhaustive and can be extended by the user.
"""
FieldProgrammingLanguages = RootModel[
    Annotated[
        list[FieldProgrammingLanguage],
        Field(
            description="A list of programming languages that can be used in the essay question. The list is not exhaustive and can be extended by the user.\n"
        ),
    ]
]

AnswerKey4 = RootModel[
    Annotated[
        str,
        Field(
            description="The answer key. It can be specified in different ways: - A single string, which is the correct answer. - An array of strings, which are all correct answers. - A regular expression, which is used to match the answer. - A null value, which denotes that the question must be graded manually.\n",
            examples=[
                "Paris",
                ["New York", "NYC"],
                {"pattern": "^Paris$", "flags": "i"},
            ],
            min_length=1,
        ),
    ]
]

Tolerance = RootModel[
    Annotated[
        str,
        Field(
            description="The tolerance for the answer. The answer is correct if it is within this tolerance of the correct answer.\n",
            examples=[0.1, "±5%", "±10.5%"],
            pattern="/^±?\\d+(\\.\\d+)?%$/",
        ),
    ]
]


class Format(Enum):
    """
    How to interpret textual strings.
    """

    md = "md"
    text = "text"


class MaxValue(Enum):
    """
    The maximum value for the grade. If the computed grade is above this value, the final  value is truncated. Null represents an unbounded value.

    """

    NoneType_None = None


class Grading(BaseModel):
    """
    Describes how the question should be graded. Usually grades are represented as a percentage between 0 and 100. In order to award different points to different questions, use the weight field instead of tweaking this field.

    """

    minValue: Annotated[
        float | Any | None,
        Field(
            description="The minimum value for the grade. If the computed grade is bellow this value, the  final value is truncated. Null represents an unbounded value.\n"
        ),
    ] = None
    maxValue: Annotated[
        float | MaxValue | None,
        Field(
            description="The maximum value for the grade. If the computed grade is above this value, the final  value is truncated. Null represents an unbounded value.\n"
        ),
    ] = None


class Footnote(BaseModel):
    id: Annotated[
        str, Field(description="An identifier for the footnote.", min_length=1)
    ]
    text: Annotated[
        str, Field(description="The text associated with the footnote.", min_length=1)
    ]


class Type(Enum):
    """
    The of the media object.
    """

    image = "image"
    video = "video"
    audio = "audio"


class MediaItem(BaseModel):
    id: Annotated[
        str, Field(description="An identifier for the media object.", min_length=1)
    ]
    type: Annotated[Type, Field(description="The of the media object.")]
    url: Annotated[
        str, Field(description="The URL for the media object.", min_length=1)
    ]
    caption: Annotated[
        str | None, Field(description="A caption for the media object.")
    ] = None


class BaseQuestion(BaseModel):
    """
    Common fields for all question types
    """

    id: Annotated[
        str,
        Field(
            description="A unique identifier for the question in the set.", min_length=1
        ),
    ]
    title: Annotated[
        str | None,
        Field(
            description="The question title. It is used to display a friendly name in the user interface. It is  different from the ID in that it is a human-readable name which is intended for displaying to the user.\n",
            min_length=1,
        ),
    ] = None
    stem: Annotated[
        str,
        Field(
            description="The main command for the question. It should be short and objective and  fits in a single paragraph. It can be written as a question or an incomplete sentence. Longer paragraphs of introductory text can be added in the preamble.\n",
            examples=[
                "Select the correct answer.",
                "How much is 2 + 2?",
                "The capital of France is...",
            ],
            min_length=1,
        ),
    ]
    type: Annotated[str, Field(description="Discriminator for the question type.")]
    format: Annotated[
        Format | None, Field(description="How to interpret textual strings.")
    ] = Format.md
    weight: Annotated[
        float | None,
        Field(
            description="The weight of the question in points. It is used to compute the final grade. The default  value is 100. The weight is multiplied by the grade of the question to compute the final  grade.\n"
        ),
    ] = 100
    grading: Annotated[
        Grading | None,
        Field(
            description="Describes how the question should be graded. Usually grades are represented as a percentage between 0 and 100. In order to award different points to different questions, use the weight field instead of tweaking this field.\n"
        ),
    ] = None
    preamble: Annotated[
        str | None,
        Field(
            description="An optional text introducing the subject matter of the question."
        ),
    ] = ""
    epilogue: Annotated[
        str | None,
        Field(description="An optional text that is shown after the question."),
    ] = ""
    comment: Annotated[
        str | None,
        Field(description="An optional text that is shown only to the teacher."),
    ] = ""
    footnotes: Annotated[
        list[Footnote] | None,
        Field(
            description="A list of footnotes declared in the preamble, epiloque or in the main text of the question.\n"
        ),
    ] = []
    media: Annotated[
        list[MediaItem] | None,
        Field(
            description="A list of media objects like images and videos that can be referenced in the question.\n"
        ),
    ] = []


class FieldBaseSelectionQuestion(BaseModel):
    """
    Common fields for questions based on selections.
    """

    shuffle: Annotated[
        bool | None,
        Field(
            description="Whether it is possible to shuffle the order of the choices."
        ),
    ] = True
    choices: Any


class SupportedLanguages(Enum):
    NoneType_None = None
    placeholder = "placeholder"


class ArtifactType(Enum):
    """
    The of artifact produced by the compilation. It is used to determine how to execute the code.

    """

    lib = "lib"
    executable = "executable"


class Compilation(BaseModel):
    """
    A dictionary mapping programming languages with their corresponding compilation environments. The options vary on a per-language basis and are encoded as somewhat arbitrary JSON objects.

    """

    class Config:
        extra = "allow"

    type: Annotated[
        str | None,
        Field(
            description="Encodes the of environment selected for the language.",
            min_length=1,
        ),
    ] = None
    artifact: Annotated[
        str | None, Field(description="Name of the produced artifact.", min_length=1)
    ] = None
    artifact_type: Annotated[
        Artifact | None,
        Field(
            alias="artifact-type",
            description="The of artifact produced by the compilation. It is used to determine how to execute the code.\n",
        ),
    ] = "executable"


class Environment(BaseModel):
    """
    A dictionary mapping programming languages with their corresponding execution environment. The options vary on a per-language basis and are encoded as arbitrary JSON objects with a required "type" key. Each language is associated with a single environment. It is up to the execution environment interpret how the environment options affect how code is  executed.

    """

    class Config:
        extra = "allow"

    type: Annotated[
        str | None,
        Field(
            description="Encodes the of environment selected for the language.",
            min_length=1,
        ),
    ] = None


class Linting(BaseModel):
    """
    A dictionary mapping programming languages with their corresponding linting options. Linting is executed on successful submissions and can discount points for style and poor practices.
    """

    class Config:
        extra = "allow"

    type: Annotated[
        str | None,
        Field(
            description="The selected linter mechanism and their options.", min_length=1
        ),
    ] = None


class Choice(BaseModel):
    text: Annotated[
        str, Field(description="The textual content for the choice", min_length=1)
    ]
    feedback: Annotated[
        str | None,
        Field(
            description="The feedback text shown to studends that selected that choice."
        ),
    ] = None
    correct: Annotated[
        Any,
        Field(
            description="Null, a boolean or value between 0 and 100, interpreted as a percentage. If  null, uses the penalty field as the value.\n"
        ),
    ]


class MultipleChoice(BaseQuestion, FieldBaseSelectionQuestion):
    """
    Multiple choice questions accept a single correct answer, which yields full grade.

    """

    type: Literal["multiple-choice"] = "multiple-choice"
    penalty: Annotated[
        float | None, Field(description="A penalty given to wrong answers")
    ] = 0
    choices: Annotated[
        list[Choice] | None,
        Field(description="The list of choices for the question", min_items=2),
    ] = None


class Input(Enum):
    """
    The of input field to be used for the essay.

    """

    text = "text"
    richtext = "richtext"
    code = "code"


class Type1(Enum):
    associative = "associative"


class Type2(Enum):
    code_io = "code-io"


class Conf(BaseModel):
    """
    A dictionary with configuration options for how the student respons will be matched with the answer key.

    """

    match_spaces: Annotated[
        bool | None,
        Field(
            alias="match-spaces",
            description="Whether to normalize when comparing the output with the expected output. If true, it ignores trailing whitespaces at each line and tries to find a tab size that would match sequences of spaces to sequences of tabs.\n",
        ),
    ] = False
    case_sensitive: Annotated[
        bool | None,
        Field(
            alias="case-sensitive",
            description="If true (default), ignore case when matching strings.\n",
        ),
    ] = True
    ignore_accents: Annotated[
        bool | None,
        Field(
            alias="ignore-accents",
            description="If true, normalize unicode strings to remove accents and diacritics.\n",
        ),
    ] = False


class AnswerKey(BaseModel):
    input: Annotated[
        str,
        Field(description="The input string be passed to the program.", min_length=1),
    ]
    output: Annotated[
        str, Field(description="The expected output for this execution.", min_length=1)
    ]


class AnswerKey1(BaseModel):
    inputs: Annotated[
        list[str],
        Field(
            description="An array with inputs that should be passed to the answer key implementation.\n",
            min_length=1,
        ),
    ]


class AnswerKey2(BaseModel):
    iospec: Annotated[
        str,
        Field(
            description="An iospec source code describing the program interaction.",
            min_length=1,
        ),
    ]


class Type3(Enum):
    unit_test = "unit-test"


class FieldTrueFalseGrading(BaseModel):
    """
    A grading strategy for true-false questions. Points are awarded in the 0-100 range.

    """

    correct: Annotated[
        float | None,
        Field(
            description="The number of points awarded for a correct answer. This is a percentage between 0 and 100.\n"
        ),
    ] = 100
    incorrect: Annotated[
        float | None,
        Field(
            description="The number of points subtracted for an incorrect answer. This is a percentage between 0 and 100.\n"
        ),
    ] = 0


class FieldChoiceQuestionItem(BaseModel):
    text: Annotated[
        str, Field(description="The textual content for the choice", min_length=1)
    ]
    feedback: Annotated[
        str | None,
        Field(
            description="The feedback text shown to studends that selected that choice."
        ),
    ] = None
    fixed: Annotated[
        bool | None,
        Field(
            description='Whether the choice is fixed in place and cannot be shuffled. This is useful for specifing options like "all of the above", "none of the above", etc. The  non-fixed choices may be shuffled.\n'
        ),
    ] = False
    correct: Any


class Type4(Enum):
    static = "static"


class FieldFillInStatic(BaseModel):
    """
    A static text snippet. It is used to display a piece of text that is not a blank.

    """

    type: Type4 | None = None
    text: Annotated[
        str | None, Field(description="The text to be displayed.", min_length=1)
    ] = None


class Type5(Enum):
    selection = "selection"


class Choice3(FieldChoiceQuestionItem):
    correct: Annotated[
        bool | None, Field(description="Specify if the choice is correct or not.")
    ] = False


class FieldFillInSelection(BaseModel):
    """
    It is used to display a selection box with a list of choices.

    """

    type: Type5 | None = None
    choices: Annotated[
        list[Choice3] | None,
        Field(description="The list of choices for the question", min_items=2),
    ] = None


class Type6(Enum):
    numeric = "numeric"


class FieldFillInNumeric(BaseModel):
    """
    Used for numeric inputs. The answer is a number and the grading is done by comparing the answer with the correct answer within a tolerance.

    """

    type: Type6 | None = None
    answer_key: Annotated[
        float | None,
        Field(
            alias="answer-key",
            description="The correct answer. This is a number and the grading is done by comparing the answer with the correct answer within a tolerance.\n",
        ),
    ] = None
    tolerance: Annotated[
        float | Tolerance | None,
        Field(
            description="The tolerance for the answer. The answer is correct if it is within this tolerance of the correct answer.\n",
            examples=[0.1, "±5%", "±10.5%"],
        ),
    ] = 0
    unit: Annotated[
        str | None,
        Field(
            description="The unit for the answer. It is usually displayed in the input box after the number.\n",
            examples=["m", "kg", "s", "meters"],
        ),
    ] = None


class Type7(Enum):
    text = "text"


class AnswerKey3(Enum):
    """
    The answer key. It can be specified in different ways: - A single string, which is the correct answer. - An array of strings, which are all correct answers. - A regular expression, which is used to match the answer. - A null value, which denotes that the question must be graded manually.

    """

    NoneType_None = None


class AnswerKey5(BaseModel):
    """
    The answer key. It can be specified in different ways: - A single string, which is the correct answer. - An array of strings, which are all correct answers. - A regular expression, which is used to match the answer. - A null value, which denotes that the question must be graded manually.

    """

    pattern: Annotated[str, Field(min_length=1)]
    flags: Annotated[str | None, Field(pattern="^[a-zA-Z]*$")] = ""


class FieldFillInText(BaseModel):
    """
    Used for text based inputs. The answer is a short string of text and the grading is done by comparing it with the reference answer key. For longer answers, please use the "essay"  question type.

    """

    type: Type7 | None = None
    answer_key: Annotated[
        AnswerKey3 | AnswerKey4 | list[str] | AnswerKey5 | None,
        Field(
            alias="answer-key",
            description="The answer key. It can be specified in different ways: - A single string, which is the correct answer. - An array of strings, which are all correct answers. - A regular expression, which is used to match the answer. - A null value, which denotes that the question must be graded manually.\n",
            examples=[
                "Paris",
                ["New York", "NYC"],
                {"pattern": "^Paris$", "flags": "i"},
            ],
        ),
    ] = None
    case_sensitive: Annotated[
        bool | None,
        Field(
            alias="case-sensitive",
            description="Whether to consider case when comparing the answer with the reference value.\n",
        ),
    ] = False


class Style(Enum):
    """
    Apply styles on how the text should be displayed.

    """

    simple = "simple"
    headline = "headline"
    code = "code"


class FieldAssociativeItemImage(BaseModel):
    url: Annotated[str, Field(description="An url relative to the question file.")]
    alt: Annotated[
        str,
        Field(
            description='The "alt" tag for the image. It is used to display a text when the image cannot be loaded and for assistive technology. The alt text is never formatted as Markdown.\n'
        ),
    ]


class FieldAssociativeItemKey(BaseModel):
    """
    Properties for association keys.
    """

    answer_key: Annotated[
        list[str] | None,
        Field(
            alias="answer-key",
            description="A list of ids representing correct associations.",
        ),
    ] = None
    feedback: Annotated[
        dict[str, str] | None,
        Field(
            description="The feedback text shown to studends that selected specific associations.\n"
        ),
    ] = None


class FieldProgrammingLanguage(Enum):
    python = "python"
    javascript = "javascript"
    java = "java"
    c = "c"
    cpp = "cpp"
    ruby = "ruby"
    go = "go"
    rust = "rust"
    php = "php"
    html = "html"
    css = "css"
    sql = "sql"
    bash = "bash"
    r = "r"
    swift = "swift"
    kotlin = "kotlin"
    typescript = "typescript"
    dart = "dart"
    scala = "scala"
    elixir = "elixir"
    clojure = "clojure"
    haskell = "haskell"
    lua = "lua"
    erlang = "erlang"
    lark = "lark"


class FieldPrivateKeys(Enum):
    """
    A list of private keys that are stripped from the document before showing it to students.  This defines a different schema since some of those keys are optional.

    """

    correct = "correct"
    answer_key = "answer-key"
    comment = "comment"
    feedback = "feedback"
    shuffle = "shuffle"
    fixed = "fixed"
    examples = "examples"
    conf = "conf"


class FieldBaseProgrammingQuestion(BaseModel):
    """
    Common fields for programming questions.
    """

    supported_languages: Annotated[
        list[SupportedLanguages | FieldProgrammingLanguages],
        Field(
            alias="supported-languages",
            description='A list of programming languages that can be used in the question. The list is not exhaustive and can be extended by the user. Null represents all languages supported by the current  platform. "placeholder" selects all languages with declared placeholders. If no placeholder is declared, this is equivalent to null.\n',
        ),
    ]
    placeholder: Annotated[
        dict[str, str] | None,
        Field(
            description="A placeholder for the code snippet. It is used to display an initial structure to students.\n",
            examples=[
                {
                    "python": 'def main():\n    x = ... # your code here\n    print("x =", x)\n'
                }
            ],
        ),
    ] = {}
    answer_key: Annotated[
        dict[str, str] | None,
        Field(
            alias="answer-key",
            description="Reference implementation used to grade the question. It is a code snippet that might be  executed to compute the expected output from some given inputs. It is a dictionary mapping programming languages with their corresponding code snippet.\n",
        ),
    ] = None
    timeout: Annotated[
        Any | float | Timeout | dict[str, float] | None,
        Field(
            description="The maximum time in seconds that the answer key can run. If the answer key runs for more than this time, it is considered to be stuck and the execution is aborted.\n"
        ),
    ] = None
    compilation: Annotated[
        Compilation | None,
        Field(
            description="A dictionary mapping programming languages with their corresponding compilation environments. The options vary on a per-language basis and are encoded as somewhat arbitrary JSON objects.\n"
        ),
    ] = None
    environment: Annotated[
        Environment | None,
        Field(
            description='A dictionary mapping programming languages with their corresponding execution environment. The options vary on a per-language basis and are encoded as arbitrary JSON objects with a required "type" key. Each language is associated with a single environment. It is up to the execution environment interpret how the environment options affect how code is  executed.\n'
        ),
    ] = None
    linting: Annotated[
        Linting | None,
        Field(
            description="A dictionary mapping programming languages with their corresponding linting options. Linting is executed on successful submissions and can discount points for style and poor practices.\n"
        ),
    ] = None
    forbidden_functions: Annotated[
        FieldForbiddenFeatures | None,
        Field(
            alias="forbidden-functions",
            description="A list of fully qualified functions that cannot be used by the student.\n",
        ),
    ] = None
    forbidden_modules: Annotated[
        FieldForbiddenFeatures | None,
        Field(
            alias="forbidden-modules",
            description="A list of fully qualified functions modules that cannot be used by the student.\n",
        ),
    ] = None
    forbidden_types: Annotated[
        FieldForbiddenFeatures | None,
        Field(
            alias="forbidden-types",
            description="A list of fully qualified types or classes that cannot be used by the student.\n",
        ),
    ] = None
    forbidden_syntax: Annotated[
        ForbiddenSyntax | ForbiddenSyntax1 | ForbiddenSyntax2 | None,
        Field(
            alias="forbidden-syntax",
            description="A mapping of keywords (if, for, etc) with the maximum number of times they can  occur in the code.\n",
        ),
    ] = None


class Grading1(BaseModel):
    """
    How the question should be graded?
    """

    strategy: Annotated[
        str | FieldTrueFalseGrading | None,
        Field(
            description="The strategy used for grading.  - strict: The user must select all correct answers and none of the incorrect ones. \n  the grade is all or nothing.\n- lenient: Each selected correct answer gives a point and each selected incorrect \n  answer subtracts a point. The grade is the number of points divided by the number \n  of correct answers.\n- true-false: Each choice is treated as a true-false question.\n"
        ),
    ] = None


class MultipleSelection(BaseQuestion, FieldBaseSelectionQuestion):
    """
    Multiple selection questions display a list of choices and a full grade is  given if the user computes all correct answers and none of the incorrect ones.

    """

    type: Annotated[str, Field(const=True)] = "multiple-selection"
    grading: Annotated[
        Grading1 | None, Field(description="How the question should be graded?")
    ] = None
    choices: Annotated[
        list[Choice3],
        Field(description="The list of choices for the question", min_items=2),
    ]


class Grading2(BaseModel):
    """
    How the question should be graded?
    """

    strategy: FieldTrueFalseGrading | None = None


class Choice2(FieldChoiceQuestionItem):
    correct: Annotated[
        bool | None, Field(description="Specify if the choice is correct or not.")
    ] = None


class TrueFalse(BaseQuestion, FieldBaseSelectionQuestion):
    """
    True-false questions display a list of choices in which the student should judge individually whether each one is true or false.

    """

    type: Annotated[str, Field(const=True)] = "true-false"
    grading: Annotated[
        Grading2 | None, Field(description="How the question should be graded?")
    ] = None
    choices: Annotated[
        list[Choice2],
        Field(description="The list of choices for the question", min_items=2),
    ]


class FillIn(BaseQuestion):
    """
    Fill-in-the-blank questions display a paragraph of text intercalated with input fields to representing blanks the user must fill in. The blanks can be of several different types.

    """

    shuffle: Annotated[
        bool | None,
        Field(
            description="Whether it is possible to shuffle the order of choices in selection boxes."
        ),
    ] = True
    body: Annotated[
        list[
            FieldFillInStatic
            | FieldFillInSelection
            | FieldFillInNumeric
            | FieldFillInText
        ],
        Field(
            description="The body of the question is formed by text snippets intercalated with input fields that represent blanks the user must fill in. The blanks can be of several different types.\n",
            min_items=1,
        ),
    ]


class Essay(BaseQuestion):
    """
    Essay questions display a text box where the user can write a long answer. The answer is graded manually.

    """

    type: Annotated[str, Field(const=True)] = "essay"
    stem: Annotated[
        str | None,
        Field(
            description="The main command for the question.\n",
            examples=["Write an essay about functional programming."],
            min_length=1,
        ),
    ] = None
    input: Annotated[
        Input | FieldProgrammingLanguages | None,
        Field(
            description="The of input field to be used for the essay.\n",
            examples=["text", "richtext", "python"],
        ),
    ] = "richtext"


class CodeIo(BaseQuestion, FieldBaseProgrammingQuestion):
    """
    A programming question that evaluates the result using by passing specific text inputs and  comparing it with the expected outputs displayed on the terminal.

    """

    type: Type2 | None = None
    conf: Annotated[
        Conf | None,
        Field(
            description="A dictionary with configuration options for how the student respons will be matched with the answer key.\n"
        ),
    ] = None
    answer_key: Annotated[
        list[AnswerKey | AnswerKey1 | AnswerKey2],
        Field(
            alias="answer-key",
            description="An array of mechanisms to produce input and output examples.\n",
            min_items=1,
        ),
    ]


class UnitTest(BaseQuestion, FieldBaseProgrammingQuestion):
    """
    A programming question that is evaluated running some unit tests.

    """

    type: Type3 | None = None
    answer_key: Annotated[
        list,
        Field(
            alias="answer-key",
            description="An array of mechanisms to produce input and output examples.\n",
            min_items=1,
        ),
    ]


class FieldAssociativeItemText(BaseModel):
    text: Annotated[str, Field(description="The text to be displayed.")]
    style: Annotated[
        Style | FieldProgrammingLanguages | None,
        Field(description="Apply styles on how the text should be displayed.\n"),
    ] = "simple"


class Associative(BaseQuestion):
    """
    Associative questions display a list of items and the user must associate each item with their corresponding answer.

    """

    type: Type1 | None = None
    shuffle: Annotated[
        bool | None,
        Field(description="Whether it is possible to shuffle the order of the items."),
    ] = True
    values: Annotated[
        dict[str, FieldAssociativeItemText | FieldAssociativeItemImage] | None,
        Field(
            description="An object with items corresponding to the right hand side of each association. The  keys represent unique identifiers.\n"
        ),
    ] = None
    keys: Annotated[
        list[Key] | None,
        Field(
            description="A list of objects representing the left hand side of the association.\n",
            min_length=1,
        ),
    ] = None


class MDQ(BaseModel):
    """
    MDQ represents a document with a sequence of questions.
    """

    class Config:
        extra = "forbid"

    id: Annotated[
        str,
        Field(
            description="A (ideally) unique identifier for the question set",
            min_length=1,
        ),
    ]
    title: Annotated[
        str | None, Field(description="A name for the collection of questions")
    ] = ""
    description: Annotated[
        str | None, Field(description="Some additional description for the exam")
    ] = ""
    preamble: Annotated[
        str | None, Field(description="An introductory text displayed to students")
    ] = ""
    tags: Annotated[
        list[str] | None,
        Field(description="Some tags that can be attached to", unique_items=True),
    ] = []
    questions: Annotated[
        list[
            MultipleChoice
            | MultipleSelection
            | TrueFalse
            | Associative
            | FillIn
            | Essay
            | CodeIo
            | UnitTest
        ],
        Field(description="List of questions", min_items=1),
    ]
