# generated by datamodel-codegen:
#   filename:  mdq.schema.json
#   timestamp: 2025-04-19T02:58:45+00:00

from __future__ import annotations

from enum import Enum
from typing import Any, Dict, List, Literal, Set

from pydantic import BaseModel, ConfigDict, Field, RootModel


class Shuffle(Enum):
    """
    Whether it is possible to shuffle the order of the items in the association.
    """
    BOTH = 'both'
    KEYS = 'keys'
    VALUES = 'values'
    NONE = 'none'


class ArtifactType(Enum):
    """
    The type of artifact produced by the compilation. It is used to determine how to execute the code.

    """
    LIB = 'lib'
    EXECUTABLE = 'executable'


class Compilation(BaseModel):
    """
    A dictionary mapping programming languages with their corresponding compilation environments. The options vary on a per-language basis and are encoded as somewhat arbitrary JSON objects.

    """
    type: str | None = Field(default=None, min_length=1)
    """
    Encodes the type of environment selected for the language.
    """
    artifact: str | None = Field(default=None, min_length=1)
    """
    Name of the produced artifact.
    """
    artifact_type: ArtifactType  = Field(default=ArtifactType.EXECUTABLE, alias='artifact-type')
    """
    The type of artifact produced by the compilation. It is used to determine how to execute the code.

    """


class Environment(BaseModel):
    """
    A dictionary mapping programming languages with their corresponding execution environment. The options vary on a per-language basis and are encoded as arbitrary JSON objects with a required "type" key. Each language is associated with a single environment. It is up to the execution environment interpret how the environment options affect how code is  executed.

    """
    type: str | None = Field(default=None, min_length=1)
    """
    Encodes the type of environment selected for the language.
    """


class Linting(BaseModel):
    """
    A dictionary mapping programming languages with their corresponding linting options. Linting is executed on successful submissions and can discount points for style and poor practices.

    """
    type: str | None = Field(default=None, min_length=1)
    """
    The selected linter mechanism and their options.
    """


class Timeout(RootModel[str]):
    root: str = Field(..., pattern='[0-9]+(.[0-9]+)?%')
    """
    The maximum time in seconds that the answer key can run. If the answer key runs for more than this time, it is considered to be stuck and the execution is aborted.

    """


class BaseSelectionItem(BaseModel):
    """
    Common fields for question items based in selection questions like multiple-choice,  multiple-selection, true-false, etc.
    """
    feedback: str = ""
    """
    The feedback text shown to students that selected that choice.
    """
    fixed: bool = False
    """
    Whether the choice is fixed in place and cannot be shuffled. This is useful for specifying options like "all of the above", "none of the above", etc. The  non-fixed choices may be shuffled.
    """
    text: str = Field(..., min_length=1)
    """
    The textual content for the choice
    """


class MultipleChoiceItem(BaseSelectionItem):
    """
    A choice for the multiple choices question. It is a text with an optional feedback.
    """
    grade: float = 0
    """
    Typically a numeric value between 0 and 100, interpreted as a percentage. If  not specified, uses the penalty field as the default grading value.

    """


class Choice(BaseSelectionItem):
    correct: bool = False
    """
    Specify if the choice is correct or not.
    """


class PrivateKeys(Enum):
    """
    A list of private keys that are stripped from the document before showing it to students.  This defines a different schema since some of those keys are required.
    """
    CORRECT = 'correct'
    GRADE = 'grade'
    ANSWER_KEY = 'answer-key'
    COMMENT = 'comment'
    FEEDBACK = 'feedback'
    SHUFFLE = 'shuffle'
    FIXED = 'fixed'
    EXAMPLES = 'examples'
    CONF = 'conf'


class AssociativeItemImage(BaseModel):
    alt: str
    """
    The "alt" tag for the image. It is used to display a text when the image cannot be loaded and for assistive technology. The alt text is never formatted as Markdown.
    """
    url: str
    """
    An url relative to the question file.
    """


class AssociativeItemText(BaseModel):
    style: str  = 'simple'
    """
    Apply styles on how the text should be displayed. Can be one of "simple", "headline" or a programming language.
    """
    text: str
    """
    The text to be displayed.
    """


class Footnote(BaseModel):
    """
    A footnote is a reference to a note at the bottom of the page. It is used to provide  additional information about a word or phrase in the text. They can be referenced in the preamble, epilogue or in the main text of the question.
    """
    id: str = Field(..., min_length=1)
    """
    An identifier for the footnote.
    """
    text: str = Field(..., min_length=1)
    """
    The text associated with the footnote.
    """


class TextFormat(Enum):
    """
    How to interpret textual strings.
    """
    MD = 'md'
    TEXT = 'text'


class GradeRange(BaseModel):
    """
    Describes how the question should be graded. Usually grades are represented as a percentage between 0 and 100. In order to award different points to different questions, use the weight field instead of tweaking this field.
    """
    max: float = 100
    """
    The maximum value for the grade. If the computed grade is above this value, the final  value is truncated. Null represents an unbounded value.
    """
    min: float = 0
    """
    The minimum value for the grade. If the computed grade is bellow this value, the  final value is truncated. Null represents an unbounded value.
    """


class CodeIoConf(BaseModel):
    """
    A dictionary with configuration options for how the student submissions will be matched with the answer key.
    """
    case_sensitive: bool = Field(default=True, alias='case-sensitive')
    """
    If true (default), ignore case when matching strings.
    """
    ignore_accents: bool = Field(default=False, alias='ignore-accents')
    """
    If true, normalize unicode strings to remove accents and diacritics.
    """
    match_spaces: bool = Field(default=False, alias='match-spaces')
    """
    Whether to normalize when comparing the output with the expected output. If true, it ignores trailing whitespaces at each line and tries to find a tab size that would match sequences of spaces to sequences of tabs.
    """


class IoAnswerKey(BaseModel):
    input: str
    """
    The input string be passed to the program.
    """
    output: str | None
    """
    The expected output for this execution.
    """


class IospecAnswerKey(BaseModel):
    iospec: str
    """
    An iospec source code describing the program interaction.
    """


class FillInInputNumeric(BaseModel):
    """
    Used for numeric inputs. The answer is a number and the grading is done by comparing the answer with the correct answer within a tolerance.
    """
    type: Literal['numeric'] = 'numeric'
    answer_key: float = Field(..., alias='answer-key')
    """
    The correct answer. This is a number and the grading is done by comparing the answer with the correct answer within a tolerance.
    """
    relative_tol: float = Field(default=0, alias='relative-tol')
    """
    The relative tolerance for the answer. The answer is correct if it is within this relative tolerance of the correct answer.
    """
    tol: float = 0
    """
    The tolerance for the answer. The answer is correct if it is within this tolerance of the correct answer.
    """
    unit: str  = Field(default='', examples=['m', 'kg', 's', 'meters'])
    """
    The unit for the answer. It is usually displayed in the input box after the number.

    """


class FillInInputSelection(BaseModel):
    """
    It is used to display a selection box with a list of choices.
    """
    type: Literal['selection'] = 'selection'
    choices: List[MultipleChoiceItem] = Field(..., min_length=2)
    """
    The list of choices for the question
    """


class FillInInputText(BaseModel):
    """
    Used for text based inputs. The answer is a short string of text and the grading is done by comparing it with the reference answer key. For longer answers, please use the "essay"  question type.
    """
    type: Literal['text'] = 'text'
    answer_key: str = Field(..., alias='answer-key')
    """
    The answer key. It can be specified in different ways: - A single string, which is the correct answer. - An array of strings, which are all correct answers. - A regular expression, which is used to match the answer. - A null value, which denotes that the question must be graded manually.
    """
    case_sensitive: bool = Field(default=False, alias='case-sensitive')
    """
    Whether to consider case when comparing the answer with the reference value.

    """


class MultipleChoiceGradingStrategy(Enum):
    """
    Describes how grades are computed from answers. Some strategies allow for multiple selections.
    * simple: 
        Student select a single choice, grade is assigned base on the "value" of the selected choice.
    * required:
        Like before, but the student must select a choice. If no choice is selected, the question 
        receives an explicit penalty.
    * average:
        Student can select multiple choices. The grade is the average of the selected choices.
    """
    SIMPLE = 'simple'
    REQUIRED = 'required'
    AVERAGE = 'average'


class TrueFalseGradingStrategy(BaseModel):
    """
    A grading strategy for true-false questions. Points are awarded in the 0-100 range.

    """
    correct: float = 100
    """
    The number of points as a percentage awarded for a correct answer.

    """
    incorrect: float = 0
    """
    The number of points as a percentage subtracted for an incorrect answer.

    """


class TrueFalseItem(BaseSelectionItem):
    """
    A choice for the true-false question. It is a text with an optional feedback.

    """
    correct: bool
    """
    Specify if the choice is correct or not.
    """


class AssociativeItemKey(BaseModel):
    """
    Properties for association keys.
    """
    answer_key: Set[str] = Field(..., alias='answer-key', min_length=1)
    """
    A list of ids representing correct associations.
    """
    feedback: Dict[str, str]  = {}
    """
    The feedback text shown to students that selected each specific associations.
    """


class MediaType(Enum):
    """
    The type of media asset.
    """
    IMAGE = 'image'
    VIDEO = 'video'
    AUDIO = 'audio'


class Grading(BaseModel):
    """
    How the question should be graded?
    """
    strategy: TrueFalseGradingStrategy  = Field(default_factory=lambda :TrueFalseGradingStrategy.model_validate({'correct': 100, 'incorrect': 0}))


class AssociativeItemKeyImage(AssociativeItemKey, AssociativeItemImage):
    pass


class AssociativeItemKeyText(AssociativeItemKey, AssociativeItemText):
    pass


class MediaObject(BaseModel):
    """
    A media object like an image or a video that can be referenced in the question.
    """
    id: str = Field(..., min_length=1)
    """
    An identifier for the media object.
    """
    type: MediaType
    caption: str = ""
    """
    An optional caption for the media object.
    """
    url: str = Field(..., min_length=1)
    """
    The URL for the media asset.
    """


class BaseQuestion(BaseModel):
    """
    Common fields for all question types. This is a base schema and should not be instantiated directly since it does not correspond to any concrete question type.
    """
    id: str = Field(..., min_length=1)
    """
    A unique identifier for the question in the set.
    """
    title: str  = Field(default='', min_length=1)
    """
    The question title. It is used to display a friendly name in the user interface. It is  different from the ID in that it is a human-readable name which is intended for displaying to the user.
    """
    type: str
    """
    Discriminator for the question type.
    """
    format: TextFormat  = TextFormat.MD
    comment: str = ""
    """
    An optional text that is shown only to the teacher.
    """
    epilogue: str = ""
    """
    An optional text that is shown after the question.
    """
    footnotes: List[Footnote]  = Field(default_factory=lambda: [])
    """
    A list of footnotes declared in the preamble, epilogue or in the main text of the question.
    """
    grade_range: GradeRange | None = Field(default=None, alias='grade-range')
    media: List[MediaObject]  = Field(default_factory=lambda: [])
    """
    A list of media objects like images and videos that can be referenced in the question.
    """
    preamble: str = ""
    """
    An optional text introducing the subject matter of the question.
    """
    stem: str = Field(..., examples=['Select the correct answer.', 'How much is 2 + 2?', 'The capital of France is...'], min_length=1)
    """
    The main command for the question. It should be short and objective and  fits in a single paragraph. It can be written as a question or an incomplete sentence. Longer paragraphs of introductory text can be added in the preamble.
    """
    tags: Set[str]  = Field(default_factory=set)
    """
    Some arbitrary tags that can be attached to the question.
    """
    weight: float = 100
    """
    The weight of the question in points. It is used to compute the final grade. The default  value is 100. The weight is multiplied by the grade of the question to compute the final  grade.
    """


class BaseSelectionQuestion(BaseQuestion):
    """
    Common fields for questions based on selections like multiple-choice, multiple-selection,  true-false, etc.
    """
    shuffle: bool = True
    """
    Whether it is possible to shuffle the order of the choices.
    """


class Essay(BaseSelectionQuestion):
    """
    Essay questions display a text box where the user can write a long answer. The answer is graded manually.
    """
    type: Literal['essay'] = 'essay'
    input: str  = Field(default='richtext', examples=['text', 'richtext', 'python'])
    """
    The type of input field to be used for the essay. It can be "text", "richtext", "code" or any specific programming language. The default is "richtext".

    """
    grade_range: GradeRange = Field(..., alias='grade-range')


class FillInTheBlankQuestion(BaseQuestion):
    """
    Fill-in-the-blank questions display a paragraph of text intercalated with input fields to representing blanks the user must fill in. The blanks can be of several different types.
    """
    body: List[FillInInputSelection | FillInInputNumeric | FillInInputText] = Field(..., min_length=1)
    """
    The body of the question is formed by text snippets intercalated with input fields that represent blanks the user must fill in. The blanks can be of several different types.
    """


class MultipleChoiceQuestion(BaseSelectionQuestion):
    """
    Multiple choice questions accept a single correct answer, which yields full grade.
    """
    type: Literal['multiple-choice'] = 'multiple-choice'
    choices: List[MultipleChoiceItem] = Field(..., min_length=2)
    """
    The list of choices for the question
    """
    grading_strategy: MultipleChoiceGradingStrategy  = Field(default=MultipleChoiceGradingStrategy.SIMPLE, alias='grading-strategy')
    penalty: float = 0
    """
    A penalty given when grading wrong answers. Penalty is a positive value that corresponds to the negative grade assigned to the wrong answers.
    """
    grade_range: GradeRange = Field(..., alias='grade-range')


class MultipleSelectionQuestion(BaseSelectionQuestion):
    """
    Multiple selection questions display a list of choices and a full grade is  given if the user computes all correct answers and none of the incorrect ones.
    """
    type: Literal['multiple-selection'] = 'multiple-selection'
    choices: List[Choice] = Field(..., min_length=2)
    """
    The list of choices for the question
    """
    grading: str  = 'strict'
    """
    The strategy used for grading.  - strict: The user must select all correct answers and none of the incorrect ones. 
      the grade is all or nothing.
    - lenient: Each selected correct answer gives a point and each selected incorrect 
      answer subtracts a point. The grade is the number of points divided by the number 
      of correct answers.
    - true-false: Each choice is treated as a true-false question.

    """
    grade_range: GradeRange = Field(..., alias='grade-range')


class TrueFalseQuestion(BaseSelectionQuestion):
    """
    True-false questions display a list of choices in which the student should judge individually whether each one is true or false.

    """
    type: Literal['true-false'] = 'true-false'
    choices: List[TrueFalseItem] = Field(..., min_length=1)
    """
    The list of choices for the question
    """
    grading: Grading | None
    """
    How the question should be graded?
    """


class AssociativeQuestion(BaseSelectionQuestion):
    """
    Associative questions display a list of items and the user must associate each item with their corresponding answer.
    """
    type: Literal['associative'] = 'associative'
    keys: List[AssociativeItemKeyText | AssociativeItemKeyImage] = Field(..., min_length=1)
    """
    A list of objects representing the left hand side of the association.
    """
    shuffle: Shuffle  = Shuffle.BOTH
    """
    Whether it is possible to shuffle the order of the items in the association.
    """
    values: Dict[str, AssociativeItemText | AssociativeItemImage]
    """
    An object with items corresponding to the right hand side of each association. The  keys represent unique identifiers.
    """


class BaseProgrammingQuestion(BaseQuestion):
    """
    Common fields for programming questions.
    """
    answer_key: Dict[str, Any] | None = Field(default=None, alias='answer-key')
    """
    Reference implementation used to grade the question. It is a code snippet that might be  executed to compute the expected output from some given inputs. It is a dictionary mapping programming languages with their corresponding code snippet.
    """
    compilation: Compilation | None
    """
    A dictionary mapping programming languages with their corresponding compilation environments. The options vary on a per-language basis and are encoded as somewhat arbitrary JSON objects.

    """
    environment: Environment | None
    """
    A dictionary mapping programming languages with their corresponding execution environment. The options vary on a per-language basis and are encoded as arbitrary JSON objects with a required "type" key. Each language is associated with a single environment. It is up to the execution environment interpret how the environment options affect how code is  executed.

    """
    forbidden_functions: Dict[str, List[str]] | None = Field(default=None, alias='forbidden-functions')
    """
    A list of fully qualified functions that cannot be used by the student.

    """
    forbidden_modules: Dict[str, List[str]] | None = Field(default=None, alias='forbidden-modules')
    """
    A list of fully qualified functions modules that cannot be used by the student.

    """
    forbidden_syntax: Dict[str, Dict[str, int]]  = Field(default={}, alias='forbidden-syntax', examples=[{'': {'if': 2, 'for': 1, 'while': 0}, 'cpp': {'if': 3, 'for': 2}}])
    """
    A mapping of languages to a map of keywords (if, for, etc) with the maximum number of  times they can occur in the code.

    """
    forbidden_types: Dict[str, List[str]] | None = Field(default=None, alias='forbidden-types')
    """
    A list of fully qualified types or classes that cannot be used by the student.

    """
    linting: Linting | None
    """
    A dictionary mapping programming languages with their corresponding linting options. Linting is executed on successful submissions and can discount points for style and poor practices.

    """
    placeholder: Dict[str, Any] | None = Field(default=None, examples=[{'python': 'def main():\n    x = ... # your code here\n    print("x =", x)\n'}])
    """
    A placeholder for the code snippet. It is used to display an initial structure to students. The special wildcard key "" defines the placeholder to all all other languages.
    """
    supported_languages: List[str] = Field(..., alias='supported-languages')
    """
    A list of programming languages that can be used in the question. The list of supported languages depends on the platform. It should be a some slug-like identifier such as  python, cpp, etc.
    Empty arrays (default) implies that only the languages with a declared placeholder or answer  key code are supported. The special array [""] implies that all supported languages are allowed.
    """
    timeout: Any | float | Timeout | None
    """
    The maximum time in seconds that the answer key can run. If the answer key runs for more than this time, it is considered to be stuck and the execution is aborted.

    """


class CodingIOQuestion(BaseProgrammingQuestion):
    """
    A programming question that evaluates the result using by passing specific text inputs and  comparing it with the expected outputs displayed on the terminal.
    """
    type: Literal['code-io'] = 'code-io'
    answer_key: List[IoAnswerKey | IospecAnswerKey] | None = Field(default=None, alias='answer-key', min_length=1)
    """
    An array of mechanisms to produce input and output examples.

    """
    conf: CodeIoConf | None


class UnitTestQuestion(BaseProgrammingQuestion):
    """
    A programming question that is evaluated running some unit tests.
    """
    model_config = ConfigDict(
        extra='forbid',
    )
    type: Literal['code-io'] = 'code-io'
    answer_key: Dict[str, Any] = Field(..., alias='answer-key')
    """
    Reference implementation used to grade the question. It is a code snippet that might be  executed to compute the expected output from some given inputs. It is a dictionary mapping programming languages with their corresponding code snippet.
    """


class Exam(BaseModel):
    """
    A MDQ Exam represents a document with a sequence of questions.
    """
    model_config = ConfigDict(
        extra='forbid',
    )
    id: str = Field(..., min_length=1)
    """
    A (ideally) unique identifier for the question set
    """
    title: str = ""
    """
    A name for the collection of questions
    """
    description: str = ""
    """
    Some additional description for the exam
    """
    preamble: str = ""
    """
    An introductory text displayed to students
    """
    questions: List[Essay | AssociativeQuestion | FillInTheBlankQuestion | MultipleChoiceQuestion | MultipleSelectionQuestion | TrueFalseQuestion | CodingIOQuestion | UnitTestQuestion] = Field(..., min_length=1)
    """
    List of questions
    """
    tags: Set[str]  = Field(default_factory=set)
    """
    Some arbitrary tags that can be attached to the exam.
    """
